{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handling\n",
    "from torch_geometric.transforms import AddSelfLoops\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from util_scripts import gnn_architectures\n",
    "from util_scripts.gnn_training import train_batch, validate_batch, calculate_multiclass_metrics, calculate_multiclass_test_metrics, export_pretty_confusion_matrix, deduplicate_multiclass_sliding_window_results, balanced_temporal_undersampler\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: General GNNs from scratch Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "LANDED_DATA_PATH = 'data/landed'\n",
    "INGESTED_DATA_PATH = 'data/ingested'\n",
    "UTILS_PATH = 'data/utils'\n",
    "SAVED_MODELS_PATH = 'saved_models'\n",
    "CONFIG_PATH = 'configs'\n",
    "\n",
    "# General parameters\n",
    "dataset_name = 'NF_ToN_IoT' # Pick from 'NF_ToN_IoT', 'NF_BoT_IoT' and 'NF_UNSW_NB15'\n",
    "truncate = True\n",
    "gnn_type = 'temporal' # Pick from 'temporal' and 'static'\n",
    "temporal = True if gnn_type == 'temporal' else False\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 10\n",
    "num_epochs = 2\n",
    "weighted_loss = True\n",
    "\n",
    "# Model Parameters. Make list of all the options you want to try\n",
    "gnn_layer_options = [2] # [2,3]\n",
    "window_size_options = [10, 1] # [10, 30]\n",
    "self_loops_options = [False]\n",
    "save_epoch_every = 1\n",
    "\n",
    "# Specific for if temporal\n",
    "window_memory_options = [3, 5] # [3, 5]\n",
    "flow_memory = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = data_handling.DataPreprocessor(INGESTED_DATA_PATH, UTILS_PATH)\n",
    "graph_builder = data_handling.GraphBuilder()\n",
    "\n",
    "attack_mapping = data_processor.load_attack_mapping(dataset_name)\n",
    "train_raw, val_raw, = data_processor.load_mixed_train(dataset_name), data_processor.load_mixed_val(dataset_name)\n",
    "(train_attrs, train_labels), (val_attrs, val_labels) = data_processor.preprocess_NF(dataset_name, train_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=truncate), \\\n",
    "                    data_processor.preprocess_NF(dataset_name, val_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=truncate)\n",
    "\n",
    "# If this dataset, we undersampxle benign flows a bit for performance. Only on training set though, not on eval!\n",
    "if dataset_name == 'NF_UNSW_NB15':\n",
    "    train_attrs, train_labels = data_processor.randomly_drop_benign_flows(train_attrs, train_labels, 0.7)\n",
    "\n",
    "for gnn_layers in gnn_layer_options:\n",
    "    gnn_hidden_channels = 128\n",
    "    classifier_layers = 2\n",
    "    classifier_hidden_channels = 128\n",
    "\n",
    "    for window_size in window_size_options:\n",
    "        for window_memory in window_memory_options:\n",
    "            window_stride = window_size\n",
    "            # batch_size = max(1,int((1/(window_size*window_memory))*200)+10) # A metric for having small enough batch size when windows are getting big\n",
    "            for self_loops in self_loops_options:\n",
    "\n",
    "                features = train_attrs.columns\n",
    "                features = [feat for feat in features if feat not in ['Dst IP', 'Dst Port', 'Flow Duration Graph Building', 'Src IP', 'Src Port', 'Timestamp']]\n",
    "                train_windows, val_windows = graph_builder.time_window_with_flow_duration(train_attrs, window_size, window_stride), \\\n",
    "                                                            graph_builder.time_window_with_flow_duration(val_attrs, window_size, window_stride)\n",
    "                if gnn_type == 'temporal':\n",
    "                    train_graphs, _ = graph_builder.build_spatio_temporal_pyg_graphs(train_windows, train_attrs, train_labels, window_memory, flow_memory, False, features, attack_mapping, True)\n",
    "                    val_graphs, val_window_indices_for_classification = graph_builder.build_spatio_temporal_pyg_graphs(val_windows, val_attrs, val_labels, window_memory, flow_memory, False, features, attack_mapping, True)\n",
    "                elif gnn_type == 'static':\n",
    "                    train_graphs = graph_builder.build_static_pyg_graphs(train_windows, train_attrs, train_labels, False, features, attack_mapping, True)\n",
    "                    val_graphs = graph_builder.build_static_pyg_graphs(val_windows, val_attrs, val_labels, False, features, attack_mapping, True)\n",
    "\n",
    "                metadata = train_graphs[0].metadata()\n",
    "                sample_graph = train_graphs[0]\n",
    "\n",
    "                if gnn_type == 'temporal':\n",
    "                    gnn_base = gnn_architectures.TemporalSAGE(metadata, gnn_hidden_channels, gnn_layers)\n",
    "                elif gnn_type == 'static':\n",
    "                    gnn_base = gnn_architectures.SAGE(metadata, gnn_hidden_channels, gnn_layers)\n",
    "                else:\n",
    "                    raise ValueError('Unknown GNN type')\n",
    "\n",
    "                model = gnn_architectures.multiclass_NIDS_model(gnn_base, len(attack_mapping), classifier_hidden_channels, classifier_layers, temporal)\n",
    "\n",
    "                os.makedirs(os.path.join(SAVED_MODELS_PATH, dataset_name, 'experiments', gnn_type), exist_ok=True)\n",
    "                model_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'experiments', gnn_type)\n",
    "                experiment_idx = len(os.listdir(model_dir))\n",
    "                experiment_dir = os.path.join(model_dir, f'experiment_{experiment_idx}')\n",
    "                os.makedirs(experiment_dir)\n",
    "                experiment_dict = {'dataset': dataset_name, 'gnn_type': gnn_type, 'gnn_layers': gnn_layers, 'gnn_hidden_channels': gnn_hidden_channels, 'classifier_layers': classifier_layers, 'classifier_hidden_channels': classifier_hidden_channels, 'self_loops': self_loops, 'window_size': window_size, 'window_stride': window_stride, 'include_port': False, 'window_memory': window_memory, 'batch_size': batch_size, 'num_epochs': num_epochs, 'weighted_loss': weighted_loss, 'truncate': truncate, 'flow_memory': flow_memory}\n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                train_weighted_f1 = []\n",
    "                val_weighted_f1 = []\n",
    "                train_macro_f1 = []\n",
    "                val_macro_f1 = []\n",
    "\n",
    "                # Setup optimizer\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "                loader_val = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                # Set model to device\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                model.to(device)\n",
    "\n",
    "                # Setup Loss Criterion\n",
    "                if weighted_loss:\n",
    "                    num_classes = len(attack_mapping)\n",
    "                    class_counts = np.zeros(num_classes)\n",
    "                    for batch in loader:\n",
    "                        target = batch['con'].y\n",
    "                        class_counts += target.sum(dim=0).cpu().numpy()\n",
    "\n",
    "                    # print(f'class counts in training data: {attack_mapping.keys()}:{class_counts}')\n",
    "                    total_samples = class_counts.sum()\n",
    "                    class_weights = total_samples / (num_classes * class_counts)\n",
    "                    weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "                    criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "                else:\n",
    "                    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "                # Train the model\n",
    "                best_model_weights_macro = None\n",
    "                best_model_weights_weighted = None\n",
    "                best_model_val_f1_macro = 0\n",
    "                best_model_val_f1_weighted = 0\n",
    "                best_model_weights_macro_epoch = 0\n",
    "                best_model_weights_weighted_epoch = 0\n",
    "\n",
    "                for epoch in tqdm(range(num_epochs)):\n",
    "                    total_train_loss = 0\n",
    "                    epoch_preds = np.array([])\n",
    "                    epoch_targets = np.array([])\n",
    "                    for batch in loader:\n",
    "                        train_data = batch.to(device)\n",
    "                        batch_loss, batch_preds, batch_targets = train_batch(model, train_data, optimizer, criterion)\n",
    "                        total_train_loss += batch_loss\n",
    "                        epoch_preds = np.concatenate((epoch_preds, batch_preds))\n",
    "                        epoch_targets = np.concatenate((epoch_targets, batch_targets))\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    epoch_train_accuracy, epoch_train_f1_weighted, epoch_train_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "                    train_losses.append(total_train_loss)\n",
    "                    train_weighted_f1.append(epoch_train_f1_weighted)\n",
    "                    train_macro_f1.append(epoch_train_f1_macro)\n",
    "                    print('Epoch:', epoch, 'Train Loss:', total_train_loss, 'Train Accuracy:', epoch_train_accuracy.item(), 'Train Multiclass Weighted F1:', epoch_train_f1_weighted.item())\n",
    "\n",
    "                    total_val_loss = 0\n",
    "                    epoch_preds = np.array([])\n",
    "                    epoch_targets = np.array([])\n",
    "                    for batch in loader_val:\n",
    "                        val_data = batch.to(device)\n",
    "                        batch_loss, batch_preds, batch_targets = validate_batch(model, val_data, criterion)\n",
    "                        total_val_loss += batch_loss\n",
    "                        epoch_preds = np.concatenate((epoch_preds, batch_preds))\n",
    "                        epoch_targets = np.concatenate((epoch_targets, batch_targets))\n",
    "\n",
    "                    val_accuracy, val_f1_weighted, val_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "                    val_losses.append(total_val_loss)\n",
    "                    val_weighted_f1.append(val_f1_weighted)\n",
    "                    val_macro_f1.append(val_f1_macro)\n",
    "                    if val_f1_macro > best_model_val_f1_macro:\n",
    "                        best_model_val_f1_macro = val_f1_macro\n",
    "                        best_model_weights_macro = model.state_dict()\n",
    "                        best_model_weights_macro_epoch = epoch\n",
    "                    if val_f1_weighted > best_model_val_f1_weighted:\n",
    "                        best_model_val_f1_weighted = val_f1_weighted\n",
    "                        best_model_weights_weighted = model.state_dict()\n",
    "                        best_model_weights_weighted_epoch = epoch\n",
    "                    if (epoch % save_epoch_every == 0) and (epoch != 0):\n",
    "                        torch.save(model.state_dict, os.path.join(experiment_dir, f'model_weights_checkpoint_epoch_{epoch}.pth'))\n",
    "\n",
    "                    print('Validation Loss:', total_val_loss, 'Validation Accuracy:', val_accuracy.item(), 'Validation Multiclass Weighted F1:', val_f1_weighted.item(), 'Validation Multiclass Macro F1:', val_f1_macro.item())\n",
    "\n",
    "                # Save the best models\n",
    "                torch.save(best_model_weights_macro, os.path.join(experiment_dir, f'best_model_weights_macro_f1_epoch_{best_model_weights_macro_epoch}.pth'))\n",
    "                torch.save(best_model_weights_weighted, os.path.join(experiment_dir, f'best_model_weights_weighted_f1_epoch_{best_model_weights_weighted_epoch}.pth'))\n",
    "\n",
    "                # Save the experiment metadata\n",
    "                experiments_results = {'train_losses': train_losses, 'val_losses': val_losses, 'train_weighted_f1': train_weighted_f1, 'val_weighted_f1': val_weighted_f1, 'train_macro_f1': train_macro_f1, 'val_macro_f1': val_macro_f1}\n",
    "                with open(os.path.join(experiment_dir, 'results.json'), 'w') as f:\n",
    "                    json.dump(experiments_results, f)\n",
    "                with open(os.path.join(experiment_dir, 'experiment_metadata.json'), 'w') as f:\n",
    "                    json.dump(experiment_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: GNNs from pre-trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "LANDED_DATA_PATH = 'data/landed'\n",
    "INGESTED_DATA_PATH = 'data/ingested'\n",
    "UTILS_PATH = 'data/utils'\n",
    "SAVED_MODELS_PATH = 'saved_models'\n",
    "CONFIG_PATH = 'configs'\n",
    "\n",
    "# General parameters\n",
    "dataset_name = 'NF_ToN_IoT' # 'NF_UNSW_NB15', 'NF_ToN_IoT', 'NF_BoT_IoT'\n",
    "pretraining_strategy = 'no_pretraining' # 'in_context','out_context','no_pretraining'\n",
    "undersample_fracs = [0.05] # [0.1, 0.2, 0.5, 0.8, 1.0] # K-shot learning\n",
    "\n",
    "# Pretrained model parameters (which one to select)\n",
    "experiment_idx = 0\n",
    "checkpoint_idx = 2\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "weighted_loss = True\n",
    "classifier_layers = 2\n",
    "classifier_hidden_channels = 128\n",
    "truncate = True # Truncate the extreme numerical values in standardization\n",
    "\n",
    "# For if pretraining_strategy=='no_pretraining'. Else, ignore (we'll load the best model from the pretraining)\n",
    "flow_memory = 20\n",
    "window_size = 5\n",
    "window_memory = 5\n",
    "window_stride = 5\n",
    "use_ports=False\n",
    "self_loops=False\n",
    "gnn_hidden_channels = 128\n",
    "gnn_type = 'temporal' # 'temporal', 'static'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = data_handling.DataPreprocessor(INGESTED_DATA_PATH, UTILS_PATH)\n",
    "graph_builder = data_handling.GraphBuilder()\n",
    "\n",
    "if pretraining_strategy != 'no_pretraining':\n",
    "  pre_trained_gnn_dir = f'{SAVED_MODELS_PATH}/{dataset_name}/pretraining_experiments/{gnn_type}/experiment_{experiment_idx}'\n",
    "  weights_path = f'{pre_trained_gnn_dir}/checkpoint_{checkpoint_idx}_gnnbase.pt'\n",
    "  metadata_path = f'{pre_trained_gnn_dir}/experiment_metadata.json'\n",
    "  with open(metadata_path, 'r') as f:\n",
    "      metadata = json.load(f)\n",
    "\n",
    "  gnn_type, flow_memory, gnn_layers, window_size, window_memory, include_port, self_loops, gnn_hidden_channels, classifier_layers, classifier_hidden_channels = metadata[\"graph_type\"],metadata[\"flow_memory\"],metadata[\"gnn_layer\"],metadata[\"window_size\"],metadata[\"window_memory\"],metadata[\"include_port\"],metadata[\"self_loops\"],metadata[\"gnn_hidden_channels\"], metadata[\"classifier_layers\"], metadata[\"classifier_hidden_channels\"]\n",
    "  window_stride = window_size\n",
    "  temporal = True if gnn_type == 'temporal' else False\n",
    "\n",
    "attack_mapping = data_processor.load_attack_mapping(dataset_name)\n",
    "truncate = True\n",
    "val_raw, test_raw = data_processor.load_mixed_val(dataset_name), data_processor.load_mixed_test(dataset_name)\n",
    "\n",
    "if pretraining_strategy != 'in_context':\n",
    "  (val_attrs, val_labels), (test_attrs, test_labels) = data_processor.preprocess_NF('all', val_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True), \\\n",
    "                            data_processor.preprocess_NF('all', test_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "else:\n",
    "  (val_attrs, val_labels), (test_attrs, test_labels) = data_processor.preprocess_NF(dataset_name, val_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True), \\\n",
    "                            data_processor.preprocess_NF(dataset_name, test_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "features = val_attrs.columns\n",
    "features = [feat for feat in features if feat not in ['Dst IP', 'Dst Port', 'Flow Duration Graph Building', 'Src IP', 'Src Port', 'Timestamp']]\n",
    "val_windows = graph_builder.time_window_with_flow_duration(val_attrs, window_size, window_stride)\n",
    "if gnn_type == 'temporal':\n",
    "    val_graphs, val_window_indices_for_classification = graph_builder.build_spatio_temporal_pyg_graphs(val_windows, val_attrs, val_labels, window_memory, flow_memory, include_port, features, attack_mapping, True)\n",
    "elif gnn_type == 'static':\n",
    "    val_graphs = graph_builder.build_static_pyg_graphs(val_windows, val_attrs, val_labels, include_port, features, attack_mapping, True)\n",
    "else:\n",
    "    raise ValueError('GNN type not recognized!')\n",
    "if self_loops:\n",
    "    val_graph = [AddSelfLoops()(graph) for graph in val_graphs]\n",
    "\n",
    "# Undersample the training data for K-shot learning\n",
    "os.makedirs(os.path.join(SAVED_MODELS_PATH, dataset_name, 'fine_tuned_experiments', gnn_type), exist_ok=True)\n",
    "experiment_idx = len(os.listdir(os.path.join(SAVED_MODELS_PATH, dataset_name, 'fine_tuned_experiments', gnn_type)))\n",
    "\n",
    "for undersample_frac in undersample_fracs:\n",
    "    train_raw = data_processor.load_mixed_train(dataset_name)\n",
    "\n",
    "    if pretraining_strategy != 'in_context':\n",
    "        train_attrs, train_labels = data_processor.preprocess_NF('all', train_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "    else:\n",
    "       train_attrs, train_labels= data_processor.preprocess_NF(dataset_name, train_raw, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "    train_attrs, train_labels, practical_fraction = balanced_temporal_undersampler(train_attrs, train_labels, undersample_frac)\n",
    "\n",
    "    features = train_attrs.columns\n",
    "    features = [feat for feat in features if feat not in ['Dst IP', 'Dst Port', 'Flow Duration Graph Building', 'Src IP', 'Src Port', 'Timestamp']]\n",
    "\n",
    "    train_windows = graph_builder.time_window_with_flow_duration(train_attrs, window_size, window_stride)\n",
    "\n",
    "    if gnn_type == 'temporal':\n",
    "        train_graphs, _ = graph_builder.build_spatio_temporal_pyg_graphs(train_windows, train_attrs, train_labels, window_memory, flow_memory, include_port, features, attack_mapping, True)\n",
    "    elif gnn_type == 'static':\n",
    "        train_graphs = graph_builder.build_static_pyg_graphs(train_windows, train_attrs, train_labels, include_port, features, attack_mapping, True)\n",
    "    else:\n",
    "        raise ValueError('GNN type not recognized!')\n",
    "\n",
    "    if self_loops:\n",
    "        train_graph = [AddSelfLoops()(graph) for graph in train_graphs]\n",
    "\n",
    "    metadata = train_graphs[0].metadata()\n",
    "    sample_graph = train_graphs[0]\n",
    "\n",
    "    if gnn_type == 'temporal':\n",
    "        gnn_base = gnn_architectures.TemporalSAGE(metadata, gnn_hidden_channels, gnn_layers)\n",
    "    elif gnn_type == 'static':\n",
    "        gnn_base = gnn_architectures.SAGE(metadata, gnn_hidden_channels, gnn_layers)\n",
    "    else:\n",
    "        raise ValueError('Unknown GNN type')\n",
    "\n",
    "    if pretraining_strategy != 'no_pretraining':\n",
    "      # Load the pre-trained model\n",
    "      with torch.no_grad():  # Initialize lazy modules.\n",
    "          out = gnn_base(sample_graph.x_dict, sample_graph.edge_index_dict)\n",
    "      gnn_base.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "      print(f'Pretrained GNN loaded successfully!')\n",
    "\n",
    "    model = gnn_architectures.multiclass_NIDS_model(gnn_base, len(attack_mapping), classifier_hidden_channels, classifier_layers)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_weighted_f1 = []\n",
    "    val_weighted_f1 = []\n",
    "    train_macro_f1 = []\n",
    "    val_macro_f1 = []\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Setup dataloader\n",
    "    loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    loader_val = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Setup Loss Criterion\n",
    "    if weighted_loss:\n",
    "        num_classes = len(attack_mapping)\n",
    "        class_counts = np.zeros(num_classes)\n",
    "        for batch in loader:\n",
    "            target = batch['con'].y\n",
    "            class_counts += target.sum(dim=0).cpu().numpy()\n",
    "\n",
    "        # print(f'class counts in training data: {attack_mapping.keys()}:{class_counts}')\n",
    "        total_samples = class_counts.sum()\n",
    "        class_weights = total_samples / (num_classes * class_counts)\n",
    "        # print(f'Class Weights: {attack_mapping.keys()}')\n",
    "        # print(class_weights)\n",
    "        weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Set model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model\n",
    "    best_model_weights = None\n",
    "    best_model_val_f1 = 0\n",
    "    best_model_weights_epoch = 0\n",
    "\n",
    "    # get the start time\n",
    "    st = time.time()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_train_loss = 0\n",
    "        epoch_preds = np.array([])\n",
    "        epoch_targets = np.array([])\n",
    "        for batch in loader:\n",
    "            train_data = batch.to(device)\n",
    "            batch_loss, batch_preds, batch_targets = train_batch(model, train_data, optimizer, criterion)\n",
    "            total_train_loss += batch_loss\n",
    "            epoch_preds = np.concatenate((epoch_preds, batch_preds))\n",
    "            epoch_targets = np.concatenate((epoch_targets, batch_targets))\n",
    "\n",
    "        # Calculate metrics\n",
    "        epoch_train_accuracy, epoch_train_f1_weighted, epoch_train_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "        train_losses.append(total_train_loss)\n",
    "        train_weighted_f1.append(epoch_train_f1_weighted)\n",
    "        train_macro_f1.append(epoch_train_f1_macro)\n",
    "        print('Epoch:', epoch, 'Train Loss:', total_train_loss, 'Train Accuracy:', epoch_train_accuracy.item(), 'Train Multiclass Weighted F1:', epoch_train_f1_weighted.item(), 'Train Multiclass Macro F1:', epoch_train_f1_macro.item())\n",
    "\n",
    "        total_val_loss = 0\n",
    "        epoch_preds = np.array([])\n",
    "        epoch_targets = np.array([])\n",
    "        for batch in loader_val:\n",
    "            val_data = batch.to(device)\n",
    "            batch_loss, batch_preds, batch_targets = validate_batch(model, val_data, criterion)\n",
    "            total_val_loss += batch_loss\n",
    "            epoch_preds = np.concatenate((epoch_preds, batch_preds))\n",
    "            epoch_targets = np.concatenate((epoch_targets, batch_targets))\n",
    "\n",
    "        val_accuracy, val_f1_weighted, val_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "        val_losses.append(total_val_loss)\n",
    "        val_weighted_f1.append(val_f1_weighted)\n",
    "        val_macro_f1.append(val_f1_macro)\n",
    "        if val_f1_macro > best_model_val_f1:\n",
    "            best_model_val_f1 = val_f1_macro\n",
    "            best_model_weights = model.state_dict()\n",
    "            best_model_weights_epoch = epoch\n",
    "        print('Validation Loss:', total_val_loss, 'Validation Accuracy:', val_accuracy.item(), 'Validation Multiclass Weighted F1:', val_f1_weighted.item(), 'Validation Multiclass Macro F1:', val_f1_macro.item())\n",
    "\n",
    "    # get the end time\n",
    "    et = time.time()\n",
    "    # get the execution time\n",
    "    elapsed_time = et - st\n",
    "    print('Execution time:', elapsed_time, 'seconds')\n",
    "\n",
    "    experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'fine_tuned_experiments', gnn_type, f'experiment_{experiment_idx}', str(undersample_frac))\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "    experiment_dict = {'dataset': dataset_name, 'K-shot-dataset_frac': practical_fraction, 'pretrain_strategy': pretraining_strategy, 'gnn_type': gnn_type, 'gnn_layers': gnn_layers, 'gnn_hidden_channels': gnn_hidden_channels, 'classifier_layers': classifier_layers, 'classifier_hidden_channels': classifier_hidden_channels, 'self_loops': self_loops, 'window_size': window_size, 'window_stride': window_stride, 'window_memory': window_memory, 'batch_size': batch_size, 'num_epochs': num_epochs, 'execution_time': elapsed_time}\n",
    "\n",
    "    # Save the best model\n",
    "    torch.save(best_model_weights, os.path.join(experiment_dir, f'best_model_weights_epoch_{best_model_weights_epoch}.pth'))\n",
    "\n",
    "    # Save the experiment metadata\n",
    "    experiments_results = {'train_losses': train_losses, 'val_losses': val_losses, 'train_weighted_f1': train_weighted_f1, 'val_weighted_f1': val_weighted_f1, 'train_macro_f1': train_macro_f1, 'val_macro_f1': val_macro_f1}\n",
    "    with open(os.path.join(experiment_dir, 'results.json'), 'w') as f:\n",
    "        json.dump(experiments_results, f)\n",
    "    with open(os.path.join(experiment_dir, 'experiment_metadata.json'), 'w') as f:\n",
    "        json.dump(experiment_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Reference MLP Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "LANDED_DATA_PATH = 'data/landed'\n",
    "INGESTED_DATA_PATH = 'data/ingested'\n",
    "UTILS_PATH = 'data/utils'\n",
    "SAVED_MODELS_PATH = 'saved_models'\n",
    "CONFIG_PATH = 'configs'\n",
    "\n",
    "# General Experiment parameters\n",
    "dataset_name = 'NF_ToN_IoT' # 'NF_ToN_IoT', 'NF_BoT_IoT' or 'NF_UNSW_NB15'\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "weighted_loss = True\n",
    "classifier_layers = 2\n",
    "classifier_hidden_channels = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = data_handling.DataPreprocessor(INGESTED_DATA_PATH, UTILS_PATH)\n",
    "graph_builder = data_handling.GraphBuilder()\n",
    "\n",
    "attack_mapping = data_processor.load_attack_mapping(dataset_name)\n",
    "\n",
    "train_raw, val_raw, test_raw = data_processor.load_mixed_train(dataset_name), data_processor.load_mixed_val(dataset_name), data_processor.load_mixed_test(dataset_name)\n",
    "\n",
    "\n",
    "(train_attrs, train_labels), (val_attrs, val_labels), (test_attrs, test_labels) = data_processor.preprocess_NF(dataset_name, train_raw, keep_IPs_and_timestamp=False, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True), \\\n",
    "            data_processor.preprocess_NF(dataset_name, val_raw, keep_IPs_and_timestamp=False, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True), \\\n",
    "            data_processor.preprocess_NF(dataset_name, test_raw, keep_IPs_and_timestamp=False, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "# Setup optimizer\n",
    "model = gnn_architectures.MLP(train_attrs.shape[1], classifier_hidden_channels, len(attack_mapping), classifier_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Make sure attrs in alphabetical order and then in tensor form\n",
    "train_attrs = train_attrs[train_attrs.columns.sort_values()]\n",
    "val_attrs = val_attrs[val_attrs.columns.sort_values()]\n",
    "test_attrs = test_attrs[test_attrs.columns.sort_values()]\n",
    "\n",
    "train_attrs = torch.tensor(train_attrs.values, dtype=torch.float32)\n",
    "train_labels = train_labels.to_numpy()\n",
    "labels_torch = torch.Tensor([attack_mapping[attack] for attack in train_labels])\n",
    "\n",
    "val_attrs = torch.tensor(val_attrs.values, dtype=torch.float32)\n",
    "val_labels = val_labels.to_numpy()\n",
    "labels_torch_val = torch.Tensor([attack_mapping[attack] for attack in val_labels])\n",
    "\n",
    "test_attrs = torch.tensor(test_attrs.values, dtype=torch.float32)\n",
    "test_labels = test_labels.to_numpy()\n",
    "labels_torch_test = torch.Tensor([attack_mapping[attack] for attack in test_labels])\n",
    "\n",
    "tensor_dataset = torch.utils.data.TensorDataset(train_attrs.float(), labels_torch.float())\n",
    "tensor_dataset_val = torch.utils.data.TensorDataset(val_attrs.float(), labels_torch_val.float())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(tensor_dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Setup Loss Criterion\n",
    "if weighted_loss:\n",
    "    num_classes = len(attack_mapping)\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    for batch in train_loader:\n",
    "        target = batch[1]\n",
    "        class_counts += target.sum(dim=0).numpy()\n",
    "\n",
    "    # print(f'class counts in training data: {attack_mapping.keys()}:{class_counts}')\n",
    "\n",
    "    total_samples = class_counts.sum()\n",
    "    class_weights = total_samples / (num_classes * class_counts)\n",
    "\n",
    "    weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "best_model_weights = None\n",
    "best_model_val_f1 = 0\n",
    "best_model_weights_epoch = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_weighted_f1 = []\n",
    "val_weighted_f1 = []\n",
    "train_macro_f1 = []\n",
    "val_macro_f1 = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_train_loss = 0\n",
    "    epoch_preds = np.array([])\n",
    "    epoch_targets = np.array([])\n",
    "    for batch in train_loader:\n",
    "        train_data, train_targets = batch\n",
    "        train_data, train_targets = train_data.to(device), train_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        batch_preds = model(train_data)\n",
    "        batch_loss = criterion(batch_preds, train_targets)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += batch_loss.item()\n",
    "        epoch_preds = np.concatenate((epoch_preds, batch_preds.argmax(dim=1).cpu().detach().numpy()))\n",
    "        epoch_targets = np.concatenate((epoch_targets, train_targets.argmax(dim=1).cpu().detach().numpy()))\n",
    "\n",
    "    # Calculate metrics\n",
    "    epoch_train_accuracy, epoch_train_f1_weighted, epoch_train_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "    train_losses.append(total_train_loss)\n",
    "    train_weighted_f1.append(epoch_train_f1_weighted)\n",
    "    train_macro_f1.append(epoch_train_f1_macro)\n",
    "    print('Epoch:', epoch, 'Train Loss:', total_train_loss, 'Train Accuracy:', epoch_train_accuracy.item(), 'Train Multiclass Weighted F1:', epoch_train_f1_weighted.item(), 'Train Multiclass Macro F1:', epoch_train_f1_macro.item())\n",
    "\n",
    "    total_val_loss = 0\n",
    "    epoch_preds = np.array([])\n",
    "    epoch_targets = np.array([])\n",
    "    for batch in val_loader:\n",
    "        val_data, val_targets = batch\n",
    "        val_data, val_targets = val_data.to(device), val_targets.to(device)\n",
    "        batch_preds = model(val_data)\n",
    "        batch_loss = criterion(batch_preds, val_targets)\n",
    "        total_val_loss += batch_loss.item()\n",
    "        epoch_preds = np.concatenate((epoch_preds, batch_preds.argmax(dim=1).cpu().detach().numpy()))\n",
    "        epoch_targets = np.concatenate((epoch_targets, val_targets.argmax(dim=1).cpu().detach().numpy()))\n",
    "\n",
    "    val_accuracy, val_f1_weighted, val_f1_macro = calculate_multiclass_metrics(epoch_preds, epoch_targets, attack_mapping)\n",
    "    val_losses.append(total_val_loss)\n",
    "    val_weighted_f1.append(val_f1_weighted)\n",
    "    val_macro_f1.append(val_f1_macro)\n",
    "    if val_f1_macro > best_model_val_f1:\n",
    "        best_model_val_f1 = val_f1_macro\n",
    "        best_model_weights = model.state_dict()\n",
    "        best_model_weights_epoch = epoch\n",
    "    print('Validation Loss:', total_val_loss, 'Validation Accuracy:', val_accuracy.item(), 'Validation Multiclass Weighted F1:', val_f1_weighted.item(), 'Validation Multiclass Macro F1:', val_f1_macro.item())\n",
    "\n",
    "os.makedirs(os.path.join(SAVED_MODELS_PATH, dataset_name, 'baselines'), exist_ok=True)\n",
    "experiment_idx = len(os.listdir(os.path.join(SAVED_MODELS_PATH, dataset_name, 'baselines')))\n",
    "experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'baselines', f'experiment_{experiment_idx}')\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "experiment_dict = {'dataset': dataset_name, 'gnn_type': 'MLP', 'gnn_layers': 0, 'gnn_hidden_channels': 0, 'classifier_layers': classifier_layers, 'classifier_hidden_channels': classifier_hidden_channels, 'batch_size': batch_size, 'num_epochs': num_epochs, 'weighted_loss': weighted_loss, 'truncate': True}\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model_weights, os.path.join(experiment_dir, f'best_model_weights_epoch_{best_model_weights_epoch}.pth'))\n",
    "\n",
    "# Save the experiment metadata\n",
    "experiments_results = {'train_losses': train_losses, 'val_losses': val_losses, 'train_weighted_f1': train_weighted_f1, 'val_weighted_f1': val_weighted_f1, 'train_macro_f1': train_macro_f1, 'val_macro_f1': val_macro_f1}\n",
    "with open(os.path.join(experiment_dir, 'results.json'), 'w') as f:\n",
    "    json.dump(experiments_results, f)\n",
    "with open(os.path.join(experiment_dir, 'experiment_metadata.json'), 'w') as f:\n",
    "    json.dump(experiment_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Model Predictions On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_evaluate = 'NF_ToN_IoT' # Choose from 'NF_ToN_IoT', 'NF_BoT_IoT', 'NF_UNSW_NB15\n",
    "model_type_to_evaluate = 'temporal' # Choose from 'static', 'temporal'\n",
    "weights_to_select = 'best_macro' # Choose from 'best_macro', 'best_weighted', or give a checkpoint number\n",
    "\n",
    "# Set the experiment directories\n",
    "gnn_from_scratch_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_to_evaluate, 'experiments', model_type_to_evaluate)\n",
    "gnn_finetune_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_to_evaluate, 'fine_tuned_experiments', model_type_to_evaluate)\n",
    "baseline_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_to_evaluate, 'baselines')\n",
    "\n",
    "# Check if the experiment directories exist\n",
    "os.makedirs(gnn_from_scratch_experiment_dir, exist_ok=True)\n",
    "os.makedirs(gnn_finetune_experiment_dir, exist_ok=True)\n",
    "os.makedirs(baseline_experiment_dir, exist_ok=True)\n",
    "\n",
    "## 1) Testing routine for all GNNs from scratch ----------\n",
    "\n",
    "for experiment_path in os.listdir(gnn_from_scratch_experiment_dir):\n",
    "    # Check which experiments have already been tested. Skip if test results already exist\n",
    "    experiment_path = os.path.join(gnn_from_scratch_experiment_dir, experiment_path)\n",
    "    files_in_experiment = os.listdir(experiment_path)\n",
    "    if 'test_set_results.pkl' in files_in_experiment:\n",
    "        print(f'Skipping {experiment_path} as test results already exist')\n",
    "        continue\n",
    "    if len(files_in_experiment) == 0:\n",
    "        print(f'Skipping {experiment_path} as no files in experiment')\n",
    "        continue\n",
    "\n",
    "    # Get Experiment Metadata\n",
    "    with open(os.path.join(experiment_path, 'experiment_metadata.json'), 'r') as f:\n",
    "        experiment_dict = json.load(f)\n",
    "\n",
    "    # Get data according to the experiment\n",
    "    test_data = data_processor.load_mixed_test(experiment_dict['dataset'])\n",
    "    attack_mapping = data_processor.load_attack_mapping(experiment_dict['dataset'])\n",
    "    if 'NF' in experiment_dict['dataset']:\n",
    "        test_attrs, test_labels = data_processor.preprocess_NF(experiment_dict['dataset'], test_data, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=experiment_dict['truncate'])\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset name')\n",
    "\n",
    "    # Get the graph list\n",
    "    test_windows = graph_builder.time_window_with_flow_duration(test_attrs, experiment_dict['window_size'], experiment_dict['window_stride'])\n",
    "    temporal = False\n",
    "    features = test_attrs.columns\n",
    "    features = [feat for feat in features if feat not in ['Dst IP', 'Dst Port', 'Flow Duration Graph Building', 'Src IP', 'Src Port', 'Timestamp']]\n",
    "    if model_type_to_evaluate == 'temporal':\n",
    "        temporal = True\n",
    "        test_graphs, test_window_indices_for_classification = graph_builder.build_spatio_temporal_pyg_graphs(test_windows, test_attrs, test_labels, experiment_dict['window_memory'], experiment_dict['flow_memory'], experiment_dict['include_port'], features, attack_mapping)\n",
    "    elif model_type_to_evaluate == 'static':\n",
    "        test_graphs = graph_builder.build_static_pyg_graphs(test_windows, test_attrs, test_labels, experiment_dict['include_port'], features, attack_mapping)\n",
    "    if experiment_dict['self_loops']:\n",
    "        test_graphs = [AddSelfLoops()(graph) for graph in test_graphs]\n",
    "    sample_graph = test_graphs[0]\n",
    "\n",
    "    # Load the model\n",
    "    if model_type_to_evaluate == 'temporal':\n",
    "        gnn_base = gnn_architectures.TemporalSAGE(sample_graph.metadata(), experiment_dict['gnn_hidden_channels'], experiment_dict['gnn_layers'])\n",
    "    elif model_type_to_evaluate == 'static':\n",
    "        gnn_base = gnn_architectures.SAGE(sample_graph.metadata(), experiment_dict['gnn_hidden_channels'], experiment_dict['gnn_layers'])\n",
    "    else:\n",
    "        raise ValueError('Unknown GNN type')\n",
    "\n",
    "    model = gnn_architectures.multiclass_NIDS_model(gnn_base, len(attack_mapping), experiment_dict['classifier_hidden_channels'], experiment_dict['classifier_layers'], temporal)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # lazy init\n",
    "    with torch.no_grad():\n",
    "        _ = model(test_graphs[0].x_dict, test_graphs[0].edge_index_dict)\n",
    "\n",
    "    # Load the best model weights\n",
    "    if weights_to_select == 'best_macro':\n",
    "        best_model_weights = [f for f in os.listdir(experiment_path) if 'macro' in f][0]\n",
    "    elif weights_to_select == 'best_weighted':\n",
    "        best_model_weights = [f for f in os.listdir(experiment_path) if 'weighted' in f][0]\n",
    "    else:\n",
    "        best_model_weights = f'model_weights_checkpoint_epoch_{weights_to_select}.pth'\n",
    "    best_model_weights = torch.load(os.path.join(experiment_path, best_model_weights), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loader = DataLoader(test_graphs, batch_size=experiment_dict['batch_size'], shuffle=False)\n",
    "    model.eval()\n",
    "    test_preds = np.array([])\n",
    "    test_targets = np.array([])\n",
    "    for idx, batch in enumerate(test_loader):\n",
    "        test_data = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(test_data.x_dict, test_data.edge_index_dict)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            if idx == 0:\n",
    "                test_probs = out.cpu().numpy()\n",
    "            else:\n",
    "                test_probs = np.concatenate((test_probs, out.cpu().numpy()), axis=0)\n",
    "            test_preds = np.concatenate((test_preds, preds.cpu().numpy()), axis=0)\n",
    "            test_targets = np.concatenate((test_targets, torch.argmax(test_data['con'].y, dim = 1).cpu().numpy()), axis=0)\n",
    "\n",
    "    # Deduplicate the results if temporal model (cause in temporal model, we have reoccurig flows connected to different windows)\n",
    "    if experiment_dict['gnn_type'] == 'temporal':\n",
    "        test_preds, test_targets, test_probs = deduplicate_multiclass_sliding_window_results(test_preds, test_targets, test_probs, test_window_indices_for_classification)\n",
    "\n",
    "    # Save test_preds, test_targets and test_probs in pickle file\n",
    "    with open(os.path.join(experiment_path, 'test_set_results.pkl'), 'wb') as f:\n",
    "        pickle.dump({'test_preds': test_preds, 'test_targets': test_targets, 'test_probs': test_probs}, f)\n",
    "\n",
    "## 2) Testing routine for all baselines --------\n",
    "\n",
    "# Change gnn_fine_tune_experiment_dir list to include all experiments including the k-shot ones that have subdirs\n",
    "experiments_dirs_in_fine_tune = []\n",
    "files_in_fine_tune = os.listdir(gnn_finetune_experiment_dir)\n",
    "for f in files_in_fine_tune:\n",
    "    if 'experiment_metadata.json' in os.listdir(os.path.join(gnn_finetune_experiment_dir, f)):\n",
    "        experiments_dirs_in_fine_tune.append(os.path.join(gnn_finetune_experiment_dir, f))\n",
    "        continue\n",
    "    subdirs = os.listdir(os.path.join(gnn_finetune_experiment_dir, f))\n",
    "    for subdir in subdirs:\n",
    "        if 'experiment_metadata.json' in os.listdir(os.path.join(gnn_finetune_experiment_dir, f, subdir)):\n",
    "            experiments_dirs_in_fine_tune.append(os.path.join(gnn_finetune_experiment_dir, f, subdir))\n",
    "\n",
    "# NOw evaluate the fine-tuned models\n",
    "for experiment_path in experiments_dirs_in_fine_tune:\n",
    "    flow_memory = 20\n",
    "    files_in_experiment = os.listdir(experiment_path)\n",
    "    # Check if already a fine-tuned model (having metadata) or a k-shot learning directory having more submodules\n",
    "    if 'experiment_metadata.json' in files_in_experiment:\n",
    "        if 'test_set_results.pkl' in files_in_experiment:\n",
    "            print(f'Skipping {experiment_path} as test results already exist')\n",
    "            continue\n",
    "        if len(files_in_experiment) == 0:\n",
    "            print(f'Skipping {experiment_path} as no files in experiment')\n",
    "            continue\n",
    "\n",
    "    # Get Experiment Metadata\n",
    "    with open(os.path.join(experiment_path, 'experiment_metadata.json'), 'r') as f:\n",
    "        experiment_dict = json.load(f)\n",
    "\n",
    "    # Get data according to the experiment\n",
    "    test_data = data_processor.load_mixed_test(experiment_dict['dataset'])\n",
    "    attack_mapping = data_processor.load_attack_mapping(experiment_dict['dataset'])\n",
    "\n",
    "    cross_data_preprocessing = False\n",
    "    if 'pretrain_strategy' in experiment_dict.keys():\n",
    "        if experiment_dict[\"pretrain_strategy\"] != 'in_context':\n",
    "            cross_data_preprocessing = True\n",
    "\n",
    "    if cross_data_preprocessing:\n",
    "        test_attrs, test_labels = data_processor.preprocess_NF('all', test_data, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "    else:\n",
    "        test_attrs, test_labels = data_processor.preprocess_NF(dataset_to_evaluate, test_data, keep_IPs_and_timestamp=True, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "\n",
    "    # Get the graph list\n",
    "    test_windows = graph_builder.time_window_with_flow_duration(test_attrs, experiment_dict['window_size'], experiment_dict['window_stride'])\n",
    "    features = test_attrs.columns\n",
    "    features = [feat for feat in features if feat not in ['Dst IP', 'Dst Port', 'Flow Duration Graph Building', 'Src IP', 'Src Port', 'Timestamp']]\n",
    "    if model_type_to_evaluate == 'temporal':\n",
    "        temporal = True\n",
    "        test_graphs, test_window_indices_for_classification = graph_builder.build_spatio_temporal_pyg_graphs(test_windows, test_attrs, test_labels, experiment_dict['window_memory'], flow_memory, False, features, attack_mapping, True)\n",
    "    elif model_type_to_evaluate == 'static':\n",
    "        temporal = False\n",
    "        test_graphs = graph_builder.build_static_pyg_graphs(test_windows, test_attrs, test_labels, experiment_dict['include_port'], features, attack_mapping)\n",
    "    if experiment_dict['self_loops']:\n",
    "        test_graphs = [AddSelfLoops()(graph) for graph in test_graphs]\n",
    "    sample_graph = test_graphs[0]\n",
    "\n",
    "    # Load the model\n",
    "    if model_type_to_evaluate == 'temporal':\n",
    "        gnn_base = gnn_architectures.TemporalSAGE(sample_graph.metadata(), experiment_dict['gnn_hidden_channels'], experiment_dict['gnn_layers'])\n",
    "    elif model_type_to_evaluate == 'static':\n",
    "        gnn_base = gnn_architectures.SAGE(sample_graph.metadata(), experiment_dict['gnn_hidden_channels'], experiment_dict['gnn_layers'])\n",
    "    else:\n",
    "        raise ValueError('Unknown GNN type')\n",
    "\n",
    "    model = gnn_architectures.multiclass_NIDS_model(gnn_base, len(attack_mapping), experiment_dict['classifier_hidden_channels'], experiment_dict['classifier_layers'], temporal)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # lazy init\n",
    "    with torch.no_grad():\n",
    "        _ = model(test_graphs[0].x_dict, test_graphs[0].edge_index_dict)\n",
    "\n",
    "    # Load the best model weights\n",
    "    best_model_weights = [f for f in os.listdir(experiment_path) if 'best_model_weights' in f][0]\n",
    "    best_model_weights = torch.load(os.path.join(experiment_path, best_model_weights), map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loader = DataLoader(test_graphs, batch_size=experiment_dict['batch_size'])\n",
    "    model.eval()\n",
    "    test_preds = np.array([])\n",
    "    test_targets = np.array([])\n",
    "    for idx,batch in enumerate(test_loader):\n",
    "        test_data = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(test_data.x_dict, test_data.edge_index_dict)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "\n",
    "            if idx == 0:\n",
    "                test_probs = out.cpu().numpy()\n",
    "            else:\n",
    "                test_probs = np.concatenate((test_probs, out.cpu().numpy()), axis=0)\n",
    "\n",
    "            test_preds = np.concatenate((test_preds, preds.cpu().numpy()), axis=0)\n",
    "            test_targets = np.concatenate((test_targets, torch.argmax(test_data['con'].y, dim = 1).cpu().numpy()), axis=0)\n",
    "\n",
    "    if experiment_dict['gnn_type'] == 'static':\n",
    "        test_preds, test_targets, test_probs = deduplicate_multiclass_sliding_window_results(test_preds, test_targets, test_probs, test_window_indices_for_classification)\n",
    "\n",
    "    # Save test_preds, test_targets and test_probs in pickle file\n",
    "    with open(os.path.join(experiment_path, 'test_set_results.pkl'), 'wb') as f:\n",
    "        pickle.dump({'test_preds': test_preds, 'test_targets': test_targets, 'test_probs': test_probs}, f)\n",
    "\n",
    "## 3) Testing routine for all baselines --------\n",
    "\n",
    "for experiment_path in os.listdir(baseline_experiment_dir):\n",
    "    experiment_path = os.path.join(baseline_experiment_dir, experiment_path)\n",
    "    files_in_experiment = os.listdir(experiment_path)\n",
    "    if 'test_set_results.pkl' in files_in_experiment:\n",
    "        print(f'Skipping {experiment_path} as test results already exist')\n",
    "        continue\n",
    "    if len(files_in_experiment) == 0:\n",
    "        print(f'Skipping {experiment_path} as no files in experiment')\n",
    "        continue\n",
    "\n",
    "    # Get Experiment Metadata\n",
    "    with open(os.path.join(experiment_path, 'experiment_metadata.json'), 'r') as f:\n",
    "        experiment_dict = json.load(f)\n",
    "\n",
    "    if experiment_dict['gnn_type'] == 'MLP':\n",
    "\n",
    "        # Get data according to the experiment\n",
    "        test_data = data_processor.load_mixed_test(experiment_dict['dataset'])\n",
    "        attack_mapping = data_processor.load_attack_mapping(experiment_dict['dataset'])\n",
    "        test_attrs, test_labels = data_processor.preprocess_NF(experiment_dict['dataset'], test_data, keep_IPs_and_timestamp=False, binary=False, remove_minority_labels=False, only_attacks=False, scale=True, truncate=True)\n",
    "        \n",
    "        # Setup model\n",
    "        model = gnn_architectures.MLP(test_attrs.shape[1], experiment_dict['classifier_hidden_channels'], len(attack_mapping), experiment_dict['classifier_layers'])\n",
    "\n",
    "        # Load the best model weights\n",
    "        best_model_weights = [f for f in os.listdir(experiment_path) if 'best_model_weights' in f][0]\n",
    "        best_model_weights = torch.load(os.path.join(experiment_path, best_model_weights), map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(best_model_weights)\n",
    "\n",
    "        # Make sure attrs in alphabetical order and then in tensor form\n",
    "        test_attrs = test_attrs[test_attrs.columns.sort_values()]\n",
    "        test_attrs = torch.tensor(test_attrs.values, dtype=torch.float32)\n",
    "        test_labels = test_labels.to_numpy()\n",
    "        labels_torch_test = torch.Tensor([attack_mapping[attack] for attack in test_labels])\n",
    "        tensor_dataset = torch.utils.data.TensorDataset(test_attrs.float(), labels_torch_test.float())\n",
    "        test_loader = torch.utils.data.DataLoader(tensor_dataset, batch_size=experiment_dict['batch_size'], shuffle=False)\n",
    "\n",
    "        # Evaluate the model\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        test_preds_list = np.array([])\n",
    "        test_targets_list = np.array([])\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            test_data, test_targets = batch\n",
    "            test_data, test_targets = test_data.to(device), test_targets.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = torch.nn.functional.softmax(model(test_data), dim=1)\n",
    "                preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "                targets = torch.argmax(test_targets, dim = 1).cpu().numpy()\n",
    "\n",
    "                if idx == 0:\n",
    "                    test_probs_list = out.cpu().numpy()\n",
    "                else:\n",
    "                    test_probs_list = np.concatenate((test_probs_list, out.cpu().numpy()), axis=0)\n",
    "\n",
    "                test_preds_list = np.concatenate((test_preds_list, preds), axis=0)\n",
    "                test_targets_list = np.concatenate((test_targets_list, targets), axis=0)\n",
    "\n",
    "\n",
    "        # Save test_preds, test_targets and test_probs in pickle file\n",
    "        with open(os.path.join(experiment_path, 'test_set_results.pkl'), 'wb') as f:\n",
    "            pickle.dump({'test_preds': test_preds_list, 'test_targets': test_targets_list, 'test_probs': test_probs_list}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Test Set Predictions to Evaluation Metrics across All Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file \n",
    "datasets_to_evaluate = ['NF_ToN_IoT'] # Choose from 'NF_ToN_IoT', 'NF_BoT_IoT', 'NF_UNSW_NB15\n",
    "model_types_to_evaluate = ['temporal'] # Choose from 'temporal' and 'static'\n",
    "weights_to_select = 'best_macro' # Choose from 'best_macro', 'best_weighted', or give a checkpoint number\n",
    "\n",
    "gnn_from_scratch_df = pd.DataFrame(columns=['dataset', 'model_type', 'window_size', 'window_memory', 'multiclass_acc', 'multiclass_f1_weighted', 'multiclass_f1_macro', 'multiclass_roc_auc_macro_ovr', 'multiclass_roc_auc_macro_ovo', 'multiclass_roc_auc_weighted_ovr', 'multiclass_roc_auc_weighted_ovo', 'binary_macro_f1', 'binary_weighted_f1'])\n",
    "baselines_df = pd.DataFrame(columns=['dataset', 'model_type', 'multiclass_acc', 'multiclass_f1_weighted', 'multiclass_f1_macro', 'multiclass_roc_auc_macro_ovr', 'multiclass_roc_auc_macro_ovo', 'multiclass_roc_auc_weighted_ovr', 'multiclass_roc_auc_weighted_ovo', 'binary_macro_f1', 'binary_weighted_f1'])\n",
    "fine_tuned_gnn_df = pd.DataFrame(columns=['dataset', 'model_type', 'window_size', 'window_memory', 'multiclass_acc', 'multiclass_f1_weighted', 'multiclass_f1_macro', 'multiclass_roc_auc_macro_ovr', 'multiclass_roc_auc_macro_ovo', 'multiclass_roc_auc_weighted_ovr', 'multiclass_roc_auc_weighted_ovo', 'binary_macro_f1', 'binary_weighted_f1'])\n",
    "k_shot_learning_df = pd.DataFrame(columns=['dataset', 'model_type', 'k_shot_frac','pretrain_strategy', 'window_size', 'window_memory','multiclass_acc', 'multiclass_f1_weighted', 'multiclass_f1_macro', 'multiclass_roc_auc_macro_ovr', 'multiclass_roc_auc_macro_ovo', 'multiclass_roc_auc_weighted_ovr', 'multiclass_roc_auc_weighted_ovo', 'binary_macro_f1', 'binary_weighted_f1', 'best_train_macro_f1', 'best_train_weighted_f1', 'best_val_macro_f1', 'best_val_weighted_f1'])\n",
    "\n",
    "for dataset_name in datasets_to_evaluate:\n",
    "    \n",
    "    for model_type_to_evaluate in model_types_to_evaluate:\n",
    "        # Set the experiment directories\n",
    "        gnn_from_scratch_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'experiments', model_type_to_evaluate)\n",
    "        gnn_finetune_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'fine_tuned_experiments', model_type_to_evaluate)\n",
    "        baseline_experiment_dir = os.path.join(SAVED_MODELS_PATH, dataset_name, 'baselines')\n",
    "\n",
    "        # Check if the experiment directories exist\n",
    "        os.makedirs(gnn_from_scratch_experiment_dir, exist_ok=True)\n",
    "        os.makedirs(gnn_finetune_experiment_dir, exist_ok=True)\n",
    "        os.makedirs(baseline_experiment_dir, exist_ok=True)\n",
    "\n",
    "        for experiment_path in os.listdir(gnn_from_scratch_experiment_dir):\n",
    "            experiment_path = os.path.join(gnn_from_scratch_experiment_dir, experiment_path)\n",
    "            with open(f'{experiment_path}/experiment_metadata.json', 'r') as f:\n",
    "                experiment_dict = json.load(f)\n",
    "\n",
    "            if 'test_set_results.pkl' not in os.listdir(experiment_path):\n",
    "                print(f'Skipping {experiment_path} with window size {experiment_dict[\"window_size\"]} and window memory {experiment_dict[\"window_memory\"]} as test results do not exist')\n",
    "                continue\n",
    "            \n",
    "            with open(f'{experiment_path}/test_set_results.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "\n",
    "\n",
    "            gnn_type, window_size, window_memory = experiment_dict['gnn_type'], experiment_dict['window_size'], experiment_dict['window_memory']\n",
    "            if window_memory == 5:\n",
    "                multiclass_acc, multiclass_f1_weighted, multiclass_f1_macro, multiclass_roc_auc_macro_ovr, multiclass_roc_auc_macro_ovo, multiclass_roc_auc_weighted_ovr, multiclass_roc_auc_weighted_ovo, binary_macro_f1, binary_weighted_f1 = calculate_multiclass_test_metrics(results['test_preds'], results['test_targets'], results['test_probs'])\n",
    "                gnn_from_scratch_df = gnn_from_scratch_df.append({'dataset':dataset_name ,'model_type': gnn_type, 'window_size': window_size, 'window_memory': window_memory, 'multiclass_acc': multiclass_acc, 'multiclass_f1_weighted': multiclass_f1_weighted, 'multiclass_f1_macro': multiclass_f1_macro, 'multiclass_roc_auc_macro_ovr': multiclass_roc_auc_macro_ovr, 'multiclass_roc_auc_macro_ovo': multiclass_roc_auc_macro_ovo, 'multiclass_roc_auc_weighted_ovr': multiclass_roc_auc_weighted_ovr, 'multiclass_roc_auc_weighted_ovo': multiclass_roc_auc_weighted_ovo, 'binary_macro_f1': binary_macro_f1, 'binary_weighted_f1': binary_weighted_f1}, ignore_index=True)\n",
    "\n",
    "        for experiment_path in os.listdir(baseline_experiment_dir):\n",
    "\n",
    "            experiment_path = os.path.join(baseline_experiment_dir, experiment_path)\n",
    "            with open(f'{experiment_path}/experiment_metadata.json', 'r') as f:\n",
    "                experiment_dict = json.load(f)\n",
    "\n",
    "            if 'test_set_results.pkl' not in os.listdir(experiment_path):\n",
    "                print(f'Skipping {experiment_path} as test results do not exist')\n",
    "                continue\n",
    "            \n",
    "            with open(f'{experiment_path}/test_set_results.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "\n",
    "            multiclass_acc, multiclass_f1_weighted, multiclass_f1_macro, multiclass_roc_auc_macro_ovr, multiclass_roc_auc_macro_ovo, multiclass_roc_auc_weighted_ovr, multiclass_roc_auc_weighted_ovo, binary_macro_f1, binary_weighted_f1 = calculate_multiclass_test_metrics(results['test_preds'], results['test_targets'], results['test_probs'])\n",
    "            baselines_df = baselines_df.append({'dataset':dataset_name ,'model_type': experiment_dict['gnn_type'], 'multiclass_acc': multiclass_acc, 'multiclass_f1_weighted': multiclass_f1_weighted, 'multiclass_f1_macro': multiclass_f1_macro, 'multiclass_roc_auc_macro_ovr': multiclass_roc_auc_macro_ovr, 'multiclass_roc_auc_macro_ovo': multiclass_roc_auc_macro_ovo, 'multiclass_roc_auc_weighted_ovr': multiclass_roc_auc_weighted_ovr, 'multiclass_roc_auc_weighted_ovo': multiclass_roc_auc_weighted_ovo, 'binary_macro_f1': binary_macro_f1, 'binary_weighted_f1': binary_weighted_f1}, ignore_index=True)\n",
    "        \n",
    "        # Change gnn_fine_tune_experiment_dir list to include all experiments including the k-shot ones that have subdirs\n",
    "        # Change gnn_fine_tune_experiment_dir list to include all experiments including the k-shot ones that have subdirs\n",
    "        experiments_dirs_in_fine_tune = []\n",
    "        files_in_fine_tune = os.listdir(gnn_finetune_experiment_dir)\n",
    "        for f in files_in_fine_tune:\n",
    "            if 'experiment_metadata.json' in os.listdir(os.path.join(gnn_finetune_experiment_dir, f)):\n",
    "                experiments_dirs_in_fine_tune.append(os.path.join(gnn_finetune_experiment_dir, f))\n",
    "                continue\n",
    "            subdirs = os.listdir(os.path.join(gnn_finetune_experiment_dir, f))\n",
    "            for subdir in subdirs:\n",
    "                if 'experiment_metadata.json' in os.listdir(os.path.join(gnn_finetune_experiment_dir, f, subdir)):\n",
    "                    experiments_dirs_in_fine_tune.append(os.path.join(gnn_finetune_experiment_dir, f, subdir))\n",
    "        for experiment_path in experiments_dirs_in_fine_tune:\n",
    "        \n",
    "            with open(f'{experiment_path}/experiment_metadata.json', 'r') as f:\n",
    "                experiment_dict = json.load(f)\n",
    "\n",
    "            k_shot_model = False\n",
    "            if 'pretrain_strategy' in experiment_dict.keys():\n",
    "                k_shot_model = True\n",
    "                with open(f'{experiment_path}/results.json', 'r') as f:\n",
    "                    train_results = json.load(f)\n",
    "\n",
    "            if 'test_set_results.pkl' not in os.listdir(experiment_path):\n",
    "                print(f'Skipping {experiment_path} with window size {experiment_dict[\"window_size\"]} and window memory {experiment_dict[\"window_memory\"]} as test results do not exist')\n",
    "                continue\n",
    "            \n",
    "            with open(f'{experiment_path}/test_set_results.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "\n",
    "            gnn_type, window_size, window_memory = experiment_dict['gnn_type'], experiment_dict['window_size'], experiment_dict['window_memory']\n",
    "\n",
    "            if k_shot_model:\n",
    "                k_shot_frac = experiment_dict['K-shot-dataset_frac']\n",
    "                pretrain_strategy = experiment_dict['pretrain_strategy']\n",
    "                multiclass_acc, multiclass_f1_weighted, multiclass_f1_macro, multiclass_roc_auc_macro_ovr, multiclass_roc_auc_macro_ovo, multiclass_roc_auc_weighted_ovr, multiclass_roc_auc_weighted_ovo, binary_macro_f1, binary_weighted_f1 = calculate_multiclass_test_metrics(results['test_preds'], results['test_targets'], results['test_probs'])\n",
    "                best_train_macro_f1, best_val_macro_f1 = max(train_results['train_macro_f1']), max(train_results['val_macro_f1'])\n",
    "                best_train_weighted_f1, best_val_weighted_f1 = max(train_results['train_weighted_f1']), max(train_results['val_weighted_f1'])\n",
    "\n",
    "                k_shot_learning_df = k_shot_learning_df.append({'dataset':dataset_name ,'model_type': gnn_type, 'k_shot_frac': k_shot_frac, 'pretrain_strategy': pretrain_strategy, 'window_size': window_size, 'window_memory': window_memory, 'multiclass_acc': multiclass_acc, 'multiclass_f1_weighted': multiclass_f1_weighted, 'multiclass_f1_macro': multiclass_f1_macro, 'multiclass_roc_auc_macro_ovr': multiclass_roc_auc_macro_ovr, 'multiclass_roc_auc_macro_ovo': multiclass_roc_auc_macro_ovo, 'multiclass_roc_auc_weighted_ovr': multiclass_roc_auc_weighted_ovr, 'multiclass_roc_auc_weighted_ovo': multiclass_roc_auc_weighted_ovo, 'binary_macro_f1': binary_macro_f1, 'binary_weighted_f1': binary_weighted_f1, 'best_train_macro_f1': best_train_macro_f1, 'best_val_macro_f1': best_val_macro_f1, 'best_train_weighted_f1': best_train_weighted_f1, 'best_val_weighted_f1': best_val_weighted_f1}, ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "                multiclass_acc, multiclass_f1_weighted, multiclass_f1_macro, multiclass_roc_auc_macro_ovr, multiclass_roc_auc_macro_ovo, multiclass_roc_auc_weighted_ovr, multiclass_roc_auc_weighted_ovo, binary_macro_f1, binary_weighted_f1 = calculate_multiclass_test_metrics(results['test_preds'], results['test_targets'], results['test_probs'])\n",
    "\n",
    "                fine_tuned_gnn_df = fine_tuned_gnn_df.append({'dataset':dataset_name ,'model_type': gnn_type, 'window_size': window_size, 'window_memory': window_memory, 'multiclass_acc': multiclass_acc, 'multiclass_f1_weighted': multiclass_f1_weighted, 'multiclass_f1_macro': multiclass_f1_macro, 'multiclass_roc_auc_macro_ovr': multiclass_roc_auc_macro_ovr, 'multiclass_roc_auc_macro_ovo': multiclass_roc_auc_macro_ovo, 'multiclass_roc_auc_weighted_ovr': multiclass_roc_auc_weighted_ovr, 'multiclass_roc_auc_weighted_ovo': multiclass_roc_auc_weighted_ovo, 'binary_macro_f1': binary_macro_f1, 'binary_weighted_f1': binary_weighted_f1}, ignore_index=True)\n",
    "\n",
    "print('GNN from scratch results')\n",
    "print(gnn_from_scratch_df)  \n",
    "print('Baselines results')\n",
    "print(baselines_df)\n",
    "print('Fine-tuned GNN results')\n",
    "print(fine_tuned_gnn_df)\n",
    "print('K-Shot Learning results')\n",
    "print(k_shot_learning_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
